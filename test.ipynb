{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier,StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "# ---- Column selector to give each pipeline its own features ----\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.cols]\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress all warnings\n",
    "os.environ['DMLC_LOG_LEVEL'] = '3'\n",
    "\n",
    "import xgboost as xgb\n",
    "# Globally set XGBoost verbosity to zero (no INFO/WARNING)\n",
    "xgb.set_config(verbosity=0)\n",
    "from sklearn_mrmr.mrmr import MRMRFeatureSelector\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# look in the data folder and take the feature you want to reduced.\n",
    "FEATURES_TO_ANALYSE = \"shape_firstorder_glcm_glrlm_features\"\n",
    "# Shape + texture features \n",
    "DATA_DIR = os.path.join(BASE_DIR,\"data\",FEATURES_TO_ANALYSE)\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR,\"TrainningDataset_reduced.csv\")\n",
    "LABEL_DIR = os.path.join(DATA_DIR,\"TrainningDatasetCategory.csv\")\n",
    "TEST_DIR = os.path.join(DATA_DIR,\"TestingDataset_reduced.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contain basic features, volumes and border of each segmentation as well as weight and age of each person.\n",
    "X = pd.read_csv(TRAIN_DIR)\n",
    "y = pd.read_csv(LABEL_DIR)\n",
    "X_test = pd.read_csv(TEST_DIR)\n",
    "\n",
    "# Assurez-vous que les identifiants sont bien formatés avec des zéros\n",
    "X[\"Id\"] = X[\"Id\"].astype(str).str.zfill(3)\n",
    "y[\"Id\"] = y[\"Id\"].astype(str).str.zfill(3)\n",
    "\n",
    "# Mélange des lignes de X\n",
    "X = X.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Réalignement parfait de y sur l’ordre de X\n",
    "y = y.set_index(\"Id\").loc[X[\"Id\"]].reset_index()\n",
    "y_train = y[\"Category\"]\n",
    "\n",
    "# Séparation des features\n",
    "X_train = X.drop(columns=[\"Id\"])\n",
    "\n",
    "X_test[\"Id\"] = X_test[\"Id\"].astype(str).str.zfill(3)\n",
    "X_test = X_test.drop(columns=[\"Id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape features selected (20): ['ED_LV_shape_VoxelVolume_over_ES_LV_shape_VoxelVolume', 'ES_RV_shape_SurfaceVolumeRatio', 'ED_LV_shape_Sphericity', 'ES_RV_shape_Maximum2DDiameterRow', 'ED_RV_shape_VoxelVolume_over_ED_LV_shape_VoxelVolume', 'ED_LV_shape_LeastAxisLength', 'ES_RV_shape_VoxelVolume_over_ED_MY_shape_VoxelVolume', 'ES_LV_shape_SurfaceVolumeRatio', 'ES_RV_shape_Sphericity', 'ED_RV_shape_VoxelVolume_over_ED_MY_shape_VoxelVolume', 'ES_LV_shape_VoxelVolume_over_ES_RV_shape_VoxelVolume', 'ES_RV_shape_MajorAxisLength', 'ED_MY_shape_VoxelVolume_over_ES_LV_shape_VoxelVolume', 'ES_LV_shape_Sphericity', 'ED_MY_shape_Flatness', 'ES_RV_shape_VoxelVolume_over_ED_RV_shape_VoxelVolume', 'ED_RV_shape_VoxelVolume_over_ES_LV_shape_VoxelVolume', 'ES_RV_shape_Maximum2DDiameterSlice', 'ES_RV_shape_VoxelVolume_over_ED_LV_shape_VoxelVolume', 'ED_LV_shape_VoxelVolume_over_ED_RV_shape_VoxelVolume']\n",
      "All features selected (20): ['ED_LV_shape_VoxelVolume_over_ES_LV_shape_VoxelVolume', 'ED_LV_firstorder_InterquartileRange', 'ES_MY_glcm_Contrast', 'ED_RV_glrlm_GrayLevelNonUniformity', 'ED_LV_shape_Sphericity', 'ES_MY_glcm_Correlation', 'ED_RV_shape_VoxelVolume_over_ED_LV_shape_VoxelVolume', 'ES_RV_shape_Maximum2DDiameterRow', 'ES_LV_shape_SurfaceVolumeRatio', 'ED_RV_shape_VoxelVolume_over_ED_MY_shape_VoxelVolume', 'ED_LV_glcm_Imc1', 'ES_LV_shape_VoxelVolume_over_ES_RV_shape_VoxelVolume', 'ED_MY_shape_VoxelVolume_over_ES_LV_shape_VoxelVolume', 'ES_RV_shape_LeastAxisLength', 'ED_LV_shape_LeastAxisLength', 'ES_RV_shape_MajorAxisLength', 'ES_RV_shape_VoxelVolume_over_ED_MY_shape_VoxelVolume', 'ES_LV_shape_Sphericity', 'ES_MY_firstorder_Kurtosis', 'ED_MY_glcm_Contrast']\n",
      "Stacking CV accuracy: 0.940 ± 0.020\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ---- Define feature groups ----\n",
    "shape_cols      = [c for c in X_train.columns if \"shape\" in c]\n",
    "all_cols        = X_train.columns.tolist()\n",
    "\n",
    "# ---- mRMR feature selection ----\n",
    "# Combine with target for pymrmr (it expects DataFrame with target column last)\n",
    "mrmr_sel = MRMRFeatureSelector(n_features_to_select=20, method='mi_quotient') \n",
    "shape_selected = list(mrmr_sel.fit_transform(X_train[shape_cols],y_train).columns)\n",
    "\n",
    "all_selected = list(mrmr_sel.fit_transform(X_train,y_train).columns)\n",
    "\n",
    "print(\"Shape features selected (20):\", shape_selected)\n",
    "print(\"All features selected (20):\", all_selected)\n",
    "# ---- Define pipelines ----\n",
    "rf_pipe = Pipeline([\n",
    "    (\"sel\", ColumnSelector(shape_selected)),\n",
    "    (\"clf\", RandomForestClassifier(class_weight=\"balanced\", random_state=0, n_jobs=-1))\n",
    "])\n",
    "svm_pipe = Pipeline([\n",
    "    (\"sel\",   ColumnSelector(all_selected)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\",   SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\", random_state=0))\n",
    "])\n",
    "xgb_pipe = Pipeline([\n",
    "    (\"sel\",   ColumnSelector(all_selected)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"clf\",   XGBClassifier(\n",
    "                   booster='gblinear',\n",
    "                   objective=\"multi:softprob\",\n",
    "                   eval_metric=\"mlogloss\",\n",
    "                   verbosity=0,\n",
    "                   random_state=0,\n",
    "                   n_jobs=-1\n",
    "               ))\n",
    "])\n",
    "\n",
    "# ---- Hyperparameter grids ----\n",
    "rf_param_grid = {\n",
    "    'clf__n_estimators':    [100, 300, 500],\n",
    "    'clf__max_depth':       [None, 5, 10],\n",
    "    'clf__min_samples_leaf':[1, 2, 4],\n",
    "}\n",
    "svm_param_grid = {\n",
    "    'clf__C':     [0.1, 1, 10,5,6,3],\n",
    "    'clf__gamma': ['scale', 0.01, 0.1,0.05]\n",
    "}\n",
    "xgb_param_grid = {\n",
    "    'clf__reg_alpha':  [0.0, 0.1, 1.0],\n",
    "    'clf__reg_lambda': [0.1, 1.0, 10.0],\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "# ---- CV setup ----\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# ---- GridSearchCV tuning ----\n",
    "rf_search = GridSearchCV(rf_pipe, rf_param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "svm_search = GridSearchCV(svm_pipe, svm_param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "xgb_search = GridSearchCV(xgb_pipe, xgb_param_grid, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "svm_search.fit(X_train, y_train)\n",
    "xgb_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf  = rf_search.best_estimator_\n",
    "best_svm = svm_search.best_estimator_\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "\n",
    "# ---- Calibrate base learners ----\n",
    "cal_rf  = CalibratedClassifierCV(best_rf, cv=5)\n",
    "cal_svm = CalibratedClassifierCV(best_svm, cv=5)\n",
    "cal_xgb = CalibratedClassifierCV(best_xgb, cv=5)\n",
    "\n",
    "# ---- True stacking ensemble ----\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf',  cal_rf),\n",
    "        ('svm', cal_svm),\n",
    "        ('xgb', cal_xgb)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    stack_method='predict_proba',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ---- Evaluate stacking ----\n",
    "scores = cross_val_score(stack, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Stacking CV accuracy: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "\n",
    "# ---- Fit and predict ----\n",
    "stack.fit(X_train, y_train)\n",
    "y_test_pred = stack.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "import os\n",
    "\n",
    "submission_name = \"submission_ensemble_stacking_v1.csv\"\n",
    "submission_dataframe = pd.DataFrame(columns=[\"Id\",\"Category\"])\n",
    "submission_dataframe[\"Id\"] = X_test.index + 101 \n",
    "\n",
    "submission_dataframe[\"Category\"] = y_test_pred\n",
    "submission_dataframe.to_csv(os.path.join(os.getcwd(),submission_name),index=False)\n",
    "\n",
    "print(\"File saved\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
