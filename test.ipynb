{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "# ---- Column selector to give each pipeline its own features ----\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.cols]\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress all warnings\n",
    "os.environ['DMLC_LOG_LEVEL'] = '3'\n",
    "\n",
    "import xgboost as xgb\n",
    "# Globally set XGBoost verbosity to zero (no INFO/WARNING)\n",
    "xgb.set_config(verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# look in the data folder and take the feature you want to reduced.\n",
    "FEATURES_TO_ANALYSE = \"shape_firstorder_glcm_glrlm_features\"\n",
    "# Shape + texture features \n",
    "DATA_DIR = os.path.join(BASE_DIR,\"data\",FEATURES_TO_ANALYSE)\n",
    "\n",
    "TRAIN_DIR = os.path.join(DATA_DIR,\"TrainningDataset_reduced.csv\")\n",
    "LABEL_DIR = os.path.join(DATA_DIR,\"TrainningDatasetCategory.csv\")\n",
    "TEST_DIR = os.path.join(DATA_DIR,\"TestingDataset_reduced.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X contain basic features, volumes and border of each segmentation as well as weight and age of each person.\n",
    "X = pd.read_csv(TRAIN_DIR)\n",
    "y = pd.read_csv(LABEL_DIR)\n",
    "X_test = pd.read_csv(TEST_DIR)\n",
    "\n",
    "# Assurez-vous que les identifiants sont bien formatés avec des zéros\n",
    "X[\"Id\"] = X[\"Id\"].astype(str).str.zfill(3)\n",
    "y[\"Id\"] = y[\"Id\"].astype(str).str.zfill(3)\n",
    "\n",
    "# Mélange des lignes de X\n",
    "X = X.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Réalignement parfait de y sur l’ordre de X\n",
    "y = y.set_index(\"Id\").loc[X[\"Id\"]].reset_index()\n",
    "y_train = y[\"Category\"]\n",
    "\n",
    "# Séparation des features\n",
    "X_train = X.drop(columns=[\"Id\"])\n",
    "\n",
    "X_test[\"Id\"] = X_test[\"Id\"].astype(str).str.zfill(3)\n",
    "X_test = X_test.drop(columns=[\"Id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ResourceTracker.__del__ at 0x102beafc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x104eb2fc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10401afc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x10a20efc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n",
      "Exception ignored in: <function ResourceTracker.__del__ at 0x11000efc0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 77, in __del__\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 86, in _stop\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/resource_tracker.py\", line 111, in _stop_locked\n",
      "ChildProcessError: [Errno 10] No child processes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Common cross-validation setup ----\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---- Build pipelines with SFS selecting 15 features per model ----\n",
    "svc_pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"sfs\",   SequentialFeatureSelector(\n",
    "                   SVC(kernel=\"linear\", class_weight=\"balanced\"),\n",
    "                   n_features_to_select=15,\n",
    "                   direction=\"forward\",\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1\n",
    "               )),\n",
    "    (\"clf\",   SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    (\"sfs\", SequentialFeatureSelector(\n",
    "                RandomForestClassifier(random_state=0),\n",
    "                n_features_to_select=15,\n",
    "                direction=\"forward\",\n",
    "                cv=cv,\n",
    "                n_jobs=-1\n",
    "            )),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "                random_state=0, class_weight=\"balanced\", n_jobs=-1\n",
    "            ))\n",
    "])\n",
    "\n",
    "xgb_pipe = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"sfs\",   SequentialFeatureSelector(\n",
    "                   XGBClassifier(eval_metric=\"mlogloss\", verbosity=0, random_state=0, n_jobs=-1),\n",
    "                   n_features_to_select=15,\n",
    "                   direction=\"forward\",\n",
    "                   cv=cv,\n",
    "                   n_jobs=-1\n",
    "               )),\n",
    "    (\"clf\",   XGBClassifier(\n",
    "                   eval_metric=\"mlogloss\", verbosity=0, random_state=0, n_jobs=-1\n",
    "               ))\n",
    "])\n",
    "\n",
    "# ---- Parameter distributions for randomized search ----\n",
    "svc_param_dist = {\n",
    "    'clf__C':     [0.1, 1, 10, 100],\n",
    "    'clf__gamma': [1e-3, 1e-2, 1e-1, 1]\n",
    "}\n",
    "rf_param_dist = {\n",
    "    'clf__n_estimators':    [100, 300, 500],\n",
    "    'clf__max_depth':       [None, 5, 10],\n",
    "    'clf__min_samples_leaf':[1, 2, 4]\n",
    "}\n",
    "xgb_param_dist = {\n",
    "    'clf__n_estimators':  [100, 300, 500],\n",
    "    'clf__max_depth':     [3, 4, 6],\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'clf__subsample':     [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# ---- Wrap pipelines in RandomizedSearchCV ----\n",
    "svc_search = RandomizedSearchCV(\n",
    "    svc_pipe, svc_param_dist, n_iter=8, cv=cv,\n",
    "    scoring='accuracy', n_jobs=-1, random_state=0\n",
    ")\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf_pipe, rf_param_dist, n_iter=8, cv=cv,\n",
    "    scoring='accuracy', n_jobs=-1, random_state=0\n",
    ")\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    xgb_pipe, xgb_param_dist, n_iter=12, cv=cv,\n",
    "    scoring='accuracy', n_jobs=-1, random_state=0\n",
    ")\n",
    "\n",
    "# ---- Soft-voting ensemble with tuned estimators ----\n",
    "voter = VotingClassifier(\n",
    "    estimators=[(\"svm\", svc_search),\n",
    "                (\"rf\",  rf_search),\n",
    "                (\"xgb\", xgb_search)],\n",
    "    voting=\"soft\", n_jobs=-1\n",
    ")\n",
    "\n",
    "# ---- CV evaluation ----\n",
    "scores = cross_val_score(voter, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "print(f\"Ensemble CV accuracy after RandomizedSearch: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "\n",
    "# ---- Fit on full training set & predict on test set ----\n",
    "voter.fit(X_train, y_train)\n",
    "y_test_pred = voter.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "import os\n",
    "\n",
    "submission_name = \"submission_ensemble_voting_v4.csv\"\n",
    "submission_dataframe = pd.DataFrame(columns=[\"Id\",\"Category\"])\n",
    "submission_dataframe[\"Id\"] = X_test.index + 101 \n",
    "\n",
    "submission_dataframe[\"Category\"] = y_test_pred\n",
    "submission_dataframe.to_csv(os.path.join(os.getcwd(),submission_name),index=False)\n",
    "\n",
    "print(\"File saved\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
